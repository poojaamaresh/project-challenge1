{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on IRIS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal_length</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.109369</td>\n",
       "      <td>0.871754</td>\n",
       "      <td>0.817954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal_width</th>\n",
       "      <td>-0.109369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.420516</td>\n",
       "      <td>-0.356544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal_length</th>\n",
       "      <td>0.871754</td>\n",
       "      <td>-0.420516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal_width</th>\n",
       "      <td>0.817954</td>\n",
       "      <td>-0.356544</td>\n",
       "      <td>0.962757</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sepal_length  sepal_width  petal_length  petal_width\n",
       "sepal_length      1.000000    -0.109369      0.871754     0.817954\n",
       "sepal_width      -0.109369     1.000000     -0.420516    -0.356544\n",
       "petal_length      0.871754    -0.420516      1.000000     0.962757\n",
       "petal_width       0.817954    -0.356544      0.962757     1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X = dataset.iloc[:, [0,1,2, 3]].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, solver='lbfgs', multi_class='auto')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "probs_y=classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : Sci-Kit learn is using a default threshold of P>0.5 for binary classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_y = np.round(probs_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test     | y_pred     | Setosa(%)  | versicolor(%) | virginica(%)\n",
      "-----------------------------------------------------------------\n",
      "virginica  | virginica  | 0.0        | 0.03          | 0.97      \n",
      "versicolor | versicolor | 0.01       | 0.95          | 0.04      \n",
      "setosa     | setosa     | 1.0        | 0.0           | 0.0       \n",
      "virginica  | virginica  | 0.0        | 0.08          | 0.92      \n",
      "setosa     | setosa     | 0.98       | 0.02          | 0.0       \n",
      "virginica  | virginica  | 0.0        | 0.01          | 0.99      \n",
      "setosa     | setosa     | 0.98       | 0.02          | 0.0       \n",
      "versicolor | versicolor | 0.01       | 0.71          | 0.28      \n",
      "versicolor | versicolor | 0.0        | 0.73          | 0.27      \n",
      "versicolor | versicolor | 0.02       | 0.89          | 0.08      \n",
      "virginica  | virginica  | 0.0        | 0.44          | 0.56      \n",
      "versicolor | versicolor | 0.02       | 0.76          | 0.22      \n",
      "versicolor | versicolor | 0.01       | 0.85          | 0.13      \n",
      "versicolor | versicolor | 0.0        | 0.69          | 0.3       \n",
      "versicolor | versicolor | 0.01       | 0.75          | 0.24      \n",
      "setosa     | setosa     | 0.95       | 0.05          | 0.0       \n",
      "versicolor | versicolor | 0.02       | 0.72          | 0.26      \n",
      "versicolor | versicolor | 0.03       | 0.86          | 0.11      \n",
      "setosa     | setosa     | 0.94       | 0.06          | 0.0       \n",
      "setosa     | setosa     | 0.99       | 0.01          | 0.0       \n",
      "virginica  | virginica  | 0.0        | 0.17          | 0.83      \n",
      "versicolor | versicolor | 0.04       | 0.71          | 0.25      \n",
      "setosa     | setosa     | 0.98       | 0.02          | 0.0       \n",
      "setosa     | setosa     | 0.96       | 0.04          | 0.0       \n",
      "virginica  | virginica  | 0.0        | 0.35          | 0.65      \n",
      "setosa     | setosa     | 1.0        | 0.0           | 0.0       \n",
      "setosa     | setosa     | 0.99       | 0.01          | 0.0       \n",
      "versicolor | versicolor | 0.02       | 0.87          | 0.11      \n",
      "versicolor | versicolor | 0.09       | 0.9           | 0.02      \n",
      "setosa     | setosa     | 0.97       | 0.03          | 0.0       \n",
      "virginica  | virginica  | 0.0        | 0.21          | 0.79      \n",
      "versicolor | versicolor | 0.06       | 0.69          | 0.25      \n",
      "setosa     | setosa     | 0.98       | 0.02          | 0.0       \n",
      "virginica  | virginica  | 0.0        | 0.35          | 0.65      \n",
      "virginica  | virginica  | 0.0        | 0.04          | 0.96      \n",
      "versicolor | versicolor | 0.07       | 0.81          | 0.11      \n",
      "setosa     | setosa     | 0.97       | 0.03          | 0.0       \n",
      "versicolor | virginica  | 0.0        | 0.42          | 0.58      \n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = \"{:<10} | {:<10} | {:<10} | {:<13} | {:<5}\".format(\"y_test\", \"y_pred\", \"Setosa(%)\", \"versicolor(%)\", \"virginica(%)\\n\")\n",
    "res += \"-\"*65+\"\\n\"\n",
    "res += \"\\n\".join(\"{:<10} | {:<10} | {:<10} | {:<13} | {:<10}\".format(x, y, a, b, c) for x, y, a, b, c in zip(y_test, y_pred, probs_y[:,0], probs_y[:,1], probs_y[:,2]))\n",
    "res += \"\\n\"+\"-\"*65+\"\\n\"\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# confusion matrix sns heatmap \n",
    "## https://www.kaggle.com/agungor2/various-confusion-matrix-plots\n",
    "ax = plt.axes()\n",
    "df_cm = cm\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 30}, fmt='d',cmap=\"Blues\", ax = ax )\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal_length</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.109369</td>\n",
       "      <td>0.871754</td>\n",
       "      <td>0.817954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal_width</th>\n",
       "      <td>-0.109369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.420516</td>\n",
       "      <td>-0.356544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal_length</th>\n",
       "      <td>0.871754</td>\n",
       "      <td>-0.420516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal_width</th>\n",
       "      <td>0.817954</td>\n",
       "      <td>-0.356544</td>\n",
       "      <td>0.962757</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sepal_length  sepal_width  petal_length  petal_width\n",
       "sepal_length      1.000000    -0.109369      0.871754     0.817954\n",
       "sepal_width      -0.109369     1.000000     -0.420516    -0.356544\n",
       "petal_length      0.871754    -0.420516      1.000000     0.962757\n",
       "petal_width       0.817954    -0.356544      0.962757     1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the features we can drop?\n",
    "X_red = dataset.iloc[:, [1,2]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red_train, X_red_test, y_train, y_test = train_test_split(X_red, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "sc_red = StandardScaler()\n",
    "X_red_train = sc_red.fit_transform(X_red_train)\n",
    "X_red_test = sc_red.transform(X_red_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_red_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Logistic Regression to the Training set\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, solver='lbfgs', multi_class='auto')\n",
    "classifier.fit(X_red_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_red_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "probs_y=classifier.predict_proba(X_red_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_y = np.round(probs_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 14  2]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.81401836, -3.11359772],\n",
       "       [-0.45621318, -0.3340972 ],\n",
       "       [-0.35780518,  3.44769492]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20789021,  1.12120656, -0.91331635])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 0,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
